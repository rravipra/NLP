# -*- coding: utf-8 -*-
"""Corruption_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14_P9_aBpnZio-Te4a4y9w-6bHfq-LyiX
"""

# import the required libraries

import pandas as pd
import numpy as np
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from scipy.sparse import vstack
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import random

dataset = []

# load the data, an example of how the data would look like is provided in the next cell

file_name = "" # the path to your train file

with open(file_name, 'r', encoding = "ISO-8859-1") as file:
    for line in file:
        sentence1, sentence2 = line.strip().split('\t') # each training example is separated by a tab character where the sentence before the tab is the original sentence and the sentence after the tab is the corrupted sentence.
        dataset.append((sentence1, sentence2))

half_size = len(dataset) // 2
original_examples = dataset[:half_size]
reversed_examples = [(s2, s1) for s1, s2 in dataset[half_size:]] # reverse the tuples for half of the data:

labeled_original_examples = [(s1, s2, 0) for s1, s2 in original_examples] # the original order is labeled as 0
labeled_reversed_examples = [(s1, s2, 1) for s1, s2 in reversed_examples] # the reversed order is labeled as 1

merged_dataset = labeled_original_examples + labeled_reversed_examples # now combine both of the data

random.seed(1)
# Shuffle the merged_dataset
random.shuffle(merged_dataset)

# Create a DataFrame from the shuffled merged_dataset
df = pd.DataFrame(merged_dataset, columns=['sentence1', 'sentence2', 'label'])

# Display the DataFrame
df.head(10)

# example of how a training example would look:
print("Sentence1: ", df.iloc[1]['sentence1'])
print("Sentence2: ", df.iloc[1]['sentence2'])
print("Label: ", df.iloc[1]['label'])
# As you can see below since the label is 0 sentence1 is the original sentence and sentence2 is the corrupted sentence, if the label is 1 it would mean the opposite.

f_name = "" # the path to your test file (the test file will be of random order i.e we don't know if the sentence 
# before the tab is the corrupted one or the sentence after the tab is the corrupted one, which is what we need to predict)

testing_data = []

# Open the text file and read it line by line
with open(f_name, "r", encoding = "ISO-8859-1") as file:
    for line in file:
        testing_data.append(line)

l1 = []
l2 = []

for t in testing_data:
  l1.append(t.strip().split("\t")[0])
  l2.append(t.strip().split("\t")[1])

df_1 = pd.DataFrame({'sentence1': l1, 'sentence2':l2})

# Load the training data
train_data = df

# Preprocess the training data
train_data['sentence1'] = train_data['sentence1'].str.lower()
train_data['sentence2'] = train_data['sentence2'].str.lower()

# Split the data into features and labels
X_train = train_data[['sentence1', 'sentence2']]
y_train = train_data['label']

# Create a TF-IDF vectorizer
vectorizer = TfidfVectorizer()

# Fit and transform the training data
X_train = vectorizer.fit_transform(train_data['sentence1'] + '<split>' + train_data['sentence2'])

# Train a logistic regression model
model = LogisticRegression(max_iter = 1000)
model.fit(X_train, y_train)

# Load the test data
test_data = df_1

# Preprocess the test data
test_data['sentence1'] = test_data['sentence1'].str.lower()
test_data['sentence2'] = test_data['sentence2'].str.lower()

# Transform the test data using the fitted vectorizer and a special token '<split>'
X_test = vectorizer.transform(test_data['sentence1'] + '<split>' + test_data['sentence2'])

# Make predictions on the test data
predictions = model.predict(X_test) # this is a list of the corresponding predicted labels for each of the test examples:

predictions # I have not shown the data here since you will have to use your own data but based on the above examples given I think that should be straight forward