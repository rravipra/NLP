{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Viterbi Algorithm for decoding under the bigram model."
      ],
      "metadata": {
        "id": "Jd5QYpcbEeDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "import operator\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "e8lv9HoXEcA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# arr stores all the bigram values line by line but it is still in string format\n",
        "file_name = \"\" # Your file path that contains the bigram and its probabilities line by line in text format\n",
        "\n",
        "# Example:\n",
        "# '<start>' '<start>' 2.1782695826435478e-05\n",
        "# '<start>' 'T' 0.20767622200923586\n",
        "# '<start>' 'h' 0.003027794719874532\n",
        "\n",
        "arr = np.loadtxt(file_name,dtype = \"str\", delimiter = \"\\n\") # load the file into an array using np.loadtxt\n",
        "bi_g = {} # bi_g contains the bi_gram model in a dictionary form\n",
        "for tup in arr:\n",
        "  bi_g[(tup.split()[0], tup.split()[1])] = float(tup.split()[2])\n",
        "bi_g"
      ],
      "metadata": {
        "id": "yVCMRcQJGy0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A file that contains each line as a sentence and each character is separated by a space. Some of the characters are labeled as '<mask>' which we need to\n",
        "# predict under the bi-gram model that maximizes the probability of the sentence.\n",
        "file_name_masked = \"\" # Path of the file that contains the masked sentences line by line\n",
        "\n",
        "# Example: <start> A <s> r e <mask> o l v i n g <s> f u n d <eos>\n",
        "# <s> denotes a space character <start> denotes the beginning or start of the sentence and <eos> denotes the end of sentence.\n",
        "\n",
        "arr_sent = np.loadtxt(file_name_masked, dtype = \"str\", delimiter = \"\\n\")"
      ],
      "metadata": {
        "id": "OW7AehvUG1C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_bi = {} \n",
        "# d_bi contains the count of each character that appears in the bi_gram, this is helpful is accessing the bi-gram characters\n",
        "# with O(1) time since it is a dictionary\n",
        "\n",
        "for k,v in bi_g.items():\n",
        "  if k[0] not in d_bi:\n",
        "    d_bi[k[0]] = 1\n",
        "  else:\n",
        "    d_bi[k[0]] += 1"
      ],
      "metadata": {
        "id": "aJr9PjD_G3rU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Viterbi algorithm function which takes in the sentence and bi_gram as parameters and returns the decoded sequence.\n",
        "\n",
        "def Viterbi(sent, bi_gram):\n",
        "  curr = ''\n",
        "  mask_list_dict = []\n",
        "  \n",
        "  for ch in sent:\n",
        "    if ch == '<start>':\n",
        "      curr = '<start>'\n",
        "      continue\n",
        "\n",
        "    if ch != '<mask>':\n",
        "      di_sub = {}\n",
        "      if not mask_list_dict:\n",
        "        di_sub[(curr, ch)] = np.log2(bi_gram[(curr, ch)])\n",
        "        mask_list_dict.append(di_sub)\n",
        "        curr = ch\n",
        "        continue\n",
        "    else:\n",
        "      di_sub = {}\n",
        "      if not mask_list_dict:\n",
        "        for k,v in bi_gram.items():\n",
        "          if k[0] == curr:\n",
        "            di_sub[k] = np.log2(v)\n",
        "        mask_list_dict.append(di_sub)\n",
        "        curr = ch\n",
        "        continue\n",
        "\n",
        "    if curr != '<mask>':\n",
        "      if ch == '<mask>':\n",
        "        mask_vec = {}\n",
        "      \n",
        "        for k,v in bi_gram.items():\n",
        "          if k[0] == curr and k[1] != \"<start>\":\n",
        "            for km, vm in mask_list_dict[len(mask_list_dict)-1].items():\n",
        "              if km[1] == curr:\n",
        "                mask_vec[k] = (np.log2(v)) + vm\n",
        "        mask_list_dict.append(mask_vec)\n",
        "        curr = ch\n",
        "        continue\n",
        "      else:\n",
        "        local_prob = bi_gram[(curr, ch)]\n",
        "        di_sub = {}\n",
        "        for km, vm in mask_list_dict[len(mask_list_dict)-1].items():\n",
        "          if km[1] == curr:\n",
        "            di_sub[(curr, ch)] = (np.log2(local_prob)) + vm \n",
        "        mask_list_dict.append(di_sub)\n",
        "        curr = ch\n",
        "        continue\n",
        "      \n",
        "    else:\n",
        "      if ch != '<mask>':\n",
        "        m_vec_sub = {}\n",
        "        mask_vec_1 = {}\n",
        "        \n",
        "        for key,val in mask_list_dict[len(mask_list_dict)-1].items():\n",
        "          m_vec_sub[(key[1],ch)] = (np.log2(bi_gram[(key[1],ch)])) + val\n",
        "        max_key = max(m_vec_sub.items(), key=operator.itemgetter(1))[0]\n",
        "        max_val = max(m_vec_sub.items(), key=operator.itemgetter(1))[1]\n",
        "        mask_vec_1 = {max_key: max_val}\n",
        "\n",
        "        mask_list_dict.append(mask_vec_1)\n",
        "        curr = ch\n",
        "        continue\n",
        "\n",
        "      else:\n",
        "          mask_vec = {}\n",
        "          \n",
        "\n",
        "          for ke, va in d_bi.items():\n",
        "            di = {}\n",
        "            for k,v in mask_list_dict[len(mask_list_dict)-1].items():\n",
        "                di[(k[1], ke)] = (np.log2(bi_gram[(k[1], ke)])) + v\n",
        "            max_k = max(di.items(), key=operator.itemgetter(1))[0]\n",
        "            max_v = max(di.items(), key=operator.itemgetter(1))[1]\n",
        "            mask_vec[max_k] = max_v\n",
        "\n",
        "          mask_list_dict.append(mask_vec)\n",
        "          curr = ch\n",
        "          continue\n",
        "\n",
        "  li_v3 = mask_list_dict\n",
        "  unmasked_v3 = []\n",
        "  curr_val = \"\"\n",
        "\n",
        "  for d in reversed(li_v3):\n",
        "    if list(d.keys())[0][1] == \"<eos>\":\n",
        "      unmasked_v3.append(list(d.keys())[0][1])\n",
        "      unmasked_v3.append(list(d.keys())[0][0])\n",
        "      curr_val = list(d.keys())[0][0]\n",
        "    else:\n",
        "      ch = list(d)[0][0]\n",
        "      unmasked_v3.append(ch)\n",
        "  s = \"\"\n",
        "  for ch in reversed(unmasked_v3):\n",
        "    s += ch + \" \"\n",
        "  return s"
      ],
      "metadata": {
        "id": "y5uyzB-mG5sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the code to store each of the decoded sentences in a list\n",
        "decoded = []\n",
        "for sent in arr_sent:\n",
        "  test_st = sent.split()\n",
        "  decoded.append(Viterbi(test_st, bi_g))"
      ],
      "metadata": {
        "id": "5NHbwxSrHGBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coverting it into a text file\n",
        "path = \"\" # The path where you want to share your decoded sentences text file.\n",
        "with open('/content/drive/MyDrive/decoded_viterbi_15pt.txt','w') as writefile:\n",
        "  for dec in decoded:\n",
        "    writefile.write(dec + \"\\n\")"
      ],
      "metadata": {
        "id": "B4X3uWzLHKk4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}