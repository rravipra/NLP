{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Unigram model. (Please read comments for further understanding)\n",
        "\n"
      ],
      "metadata": {
        "id": "rO9rSi1-x9-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# author: Rthvik Raviprakash\n",
        "# email: rthvik.07@gmail.com\n",
        "# date: 02/25/2023"
      ],
      "metadata": {
        "id": "LySfTg9jyTEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the required libraries\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "9PLHZFlDx8XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import nltk if required. I am not using it since I build my uni-gram model from scratch. nltk is a good way to cross check\n",
        "# if your perplexity is in an acceptable range.\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDpIRaIfnYZE",
        "outputId": "a6838d69-ebb0-4b2e-e81b-cb00f2f9fc35"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_str = \"\" # The path of the file that contains that training tokens. In my case it is of sentences form line by line.\n",
        "a = np.loadtxt(file_str,dtype = \"str\", delimiter = \"\\n\") # The output shown is an example from the file that I had used.\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMDy1elXnbCh",
        "outputId": "da4421b9-5cd1-4175-8310-bb68581cafe0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Having a little flexibility on that issue would go a long way to putting together a final package .',\n",
              "       'Long before the advent of e-commerce , Wal-Mart \\'s founder Sam Walton set out his vision for a successful retail operation : \" We let folks know we \\'re interested in them and that they \\'re vital to us-- \\' cause they are , \" he said .',\n",
              "       'A spokesman said the company has been affected by the credit crunch in the United States .',\n",
              "       ..., 'Wisconsin ( 11 ) vs Ohio St. , 4 p.m.',\n",
              "       'Of course , they think that a lot of this stuff is genetic .',\n",
              "       'By the age of seven , the boy had been seen by doctors more than 325 times and undergone nine operations .'],\n",
              "      dtype='<U2467')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unigram counts of each word in the vocabulary\n",
        "cnt = {}\n",
        "with open(file_str) as file:\n",
        "  for line in file:\n",
        "    a = line.split()\n",
        "    a.append('<s t o p>')\n",
        "    ar_sub = ['<s t a r t>'] + a\n",
        "    for value in ar_sub:\n",
        "      if value not in cnt:\n",
        "        cnt[value] = 1\n",
        "      else:\n",
        "        cnt[value] += 1"
      ],
      "metadata": {
        "id": "NfkgksCMnc_x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A dictionary of unknown words\n",
        "k = 5 # You can change the value of k based on what you want to consider and unknown token to be. (In my case k = 5 which means that any\n",
        "# word that occurs less than 5 times in the whole document I will give in an \"<unk>\" token)\n",
        "word_dict = {word : \"<u n k>\" for word, occurrences in cnt.items() if occurrences < k}"
      ],
      "metadata": {
        "id": "cxCm0_QKoDfs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The vocab counts is a dictionoary that contains the counts of each unique word in the document (which is basically the vocabulary).\n",
        "vocab_counts = {}\n",
        "vocab_counts['<u n k>'] = 0\n",
        "\n",
        "for k,v in cnt.items():\n",
        "  if v >= 5:\n",
        "    vocab_counts[k] = v\n",
        "  else:\n",
        "    vocab_counts['<u n k>'] += v"
      ],
      "metadata": {
        "id": "EtjgfkIcoR_Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 0\n",
        "for k,v in vocab_counts.items():\n",
        "  N += v # N is the total number of words in the document (Note: this is not the unique number of words that are in the document, since that would be V)\n",
        "\n",
        "p_unk = vocab_counts['<u n k>']/N\n",
        "\n",
        "# Unigram Model\n",
        "V = len(vocab_counts) # This is the total number of words in the vocabulary\n",
        "words_li = []\n",
        "prob_li = []\n",
        "\n",
        "word_prob_uni = {}\n",
        "\n",
        "for k,v in vocab_counts.items():\n",
        "  words_li.append(k)\n",
        "  prob_li.append(v/N)\n",
        "  word_prob_uni[k] = v/N\n",
        "\n",
        "di = {'Word': words_li, 'Probability' : prob_li}\n",
        "df = pd.DataFrame(data = di) # This dataframe consists of each word(token) and it's respective probabilities under the unigram model.\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "WXkSfg8RoSt3",
        "outputId": "92d32f79-f7e7-41db-84c7-2413810f0172"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Word  Probability\n",
              "0          <u n k>     0.055330\n",
              "1      <s t a r t>     0.036529\n",
              "2           Having     0.000028\n",
              "3                a     0.018674\n",
              "4           little     0.000275\n",
              "...            ...          ...\n",
              "18115      paraded     0.000003\n",
              "18116          CSR     0.000003\n",
              "18117         SiRF     0.000003\n",
              "18118     helpless     0.000003\n",
              "18119     hideouts     0.000003\n",
              "\n",
              "[18120 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44cf3d0b-93dc-42ae-8401-5a74706bf55d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;u n k&gt;</td>\n",
              "      <td>0.055330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s t a r t&gt;</td>\n",
              "      <td>0.036529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Having</td>\n",
              "      <td>0.000028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a</td>\n",
              "      <td>0.018674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>little</td>\n",
              "      <td>0.000275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18115</th>\n",
              "      <td>paraded</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18116</th>\n",
              "      <td>CSR</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18117</th>\n",
              "      <td>SiRF</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18118</th>\n",
              "      <td>helpless</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18119</th>\n",
              "      <td>hideouts</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18120 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44cf3d0b-93dc-42ae-8401-5a74706bf55d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44cf3d0b-93dc-42ae-8401-5a74706bf55d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44cf3d0b-93dc-42ae-8401-5a74706bf55d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Perplexity\n",
        "import numpy as np\n",
        "log_sum = 0\n",
        "for i in range(len(prob_li)):\n",
        "  log_sum += np.log(prob_li[i])*vocab_counts[words_li[i]]\n",
        "\n",
        "ppx_uni_train = np.exp((-1/N)*log_sum)\n",
        "\n",
        "print(\"The unigram perplexity on the training set: \", round(ppx_uni_train, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voaszoyVoXWh",
        "outputId": "c39d6715-7d3e-4eb1-ad66-7b543ade2daa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The unigram perplexity on the training set:  736.104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This function takes in a sentence and a dictionary that contains words labeled as unknown and returns the trigrams for that sentence\n",
        "# For example: If we have a sentence: \"This is a unigram model.\" it would return a list [(\"<start>\", \"<start>\", \"<start>\"), (\"<start>\", \"<start>\", \"This\")\n",
        "# (\"<start>\", \"This\", \"is\"), (\"This\", \"is\", \"a\"), (\"is\", \"a\", \"unigram\"), (\"a\", \"unigram\", \"model\"), (\"unigram\", \"model\", \"<stop>\")]\n",
        "# If any of the words in that sentence exists in the unknown dictionary, it will return with that word's label as \"<unk>\"\n",
        "\n",
        "def token_tri(sentence, unk_dict):\n",
        "  arr_sub = sentence.split()\n",
        "  arr_sub.append(\"<s t o p>\")\n",
        "  arr_tri = [\"<s t a r t>\", \"<s t a r t>\"] + arr_sub\n",
        "  tri_gram = []\n",
        "\n",
        "  if len(arr_tri) == 3:\n",
        "    return []\n",
        "  j = 0\n",
        "\n",
        "  while j < len(arr_tri) - 2:\n",
        "    if arr_tri[j] not in unk_dict:\n",
        "      if arr_tri[j + 1] not in unk_dict:\n",
        "        if arr_tri[j+2] not in unk_dict:\n",
        "          tri_gram.append((arr_tri[j], arr_tri[j+1], arr_tri[j+2]))\n",
        "        else:\n",
        "          tri_gram.append((arr_tri[j], arr_tri[j+1], '<u n k>'))\n",
        "      else:\n",
        "        if arr_tri[j+2] not in unk_dict:\n",
        "          tri_gram.append((arr_tri[j],'<u n k>' , arr_tri[j+2]))\n",
        "        else:\n",
        "          tri_gram.append((arr_tri[j], '<u n k>', '<u n k>'))\n",
        "      j += 1\n",
        "    else:\n",
        "      if arr_tri[j + 1] not in unk_dict:\n",
        "        if arr_tri[j+2] not in unk_dict:\n",
        "          tri_gram.append(('<u n k>', arr_tri[j+1], arr_tri[j+2]))\n",
        "        else:\n",
        "          tri_gram.append(('<u n k>', arr_tri[j+1], '<u n k>'))\n",
        "      else:\n",
        "        if arr_tri[j+2] not in unk_dict:\n",
        "          tri_gram.append(('<u n k>','<u n k>' , arr_tri[j+2]))\n",
        "        else:\n",
        "          tri_gram.append(('<u n k>', '<u n k>', '<u n k>'))\n",
        "      j += 1\n",
        "\n",
        "  return tri_gram"
      ],
      "metadata": {
        "id": "WM5YfXVnqij8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataframe of uni, bi and tri of each word with it's probabilities\n",
        "\n",
        "# I am using Laplace smoothing for the words that don't exist in the training set but occurs in the test set to avoid having zeros.\n",
        "\n",
        "test_file = \"\" # The path of the file that contains that test tokens. In my case it is of sentences form line by line.\n",
        "\n",
        "prob_uni_test = []\n",
        "prob_bi_test = []\n",
        "prob_tri_test = []\n",
        "uni_word_test = []\n",
        "bi_word_test = []\n",
        "tri_word_test = []\n",
        "alpha = 1 # This value is a hyperparameter which can be tuned using the development data.\n",
        "\n",
        "# So using the same code that I am using for the test set you can load in your development set data instead of the test set data\n",
        "# and tune your hyperparameters.\n",
        "\n",
        "with open(test_file) as file:\n",
        "  for line in file:\n",
        "    arr = token_tri(line, word_dict)\n",
        "    for tri in arr:\n",
        "      uni_word_test.append((tri[2]))\n",
        "      uni = tri[2]\n",
        "\n",
        "      if uni in word_prob_uni:\n",
        "        prob_uni_test.append(word_prob_uni[uni])\n",
        "      else:\n",
        "        prob_uni_test.append(alpha/(N + V))\n",
        "      \n",
        "di_uni_test = {'Word_uni_test': uni_word_test, 'Prob_uni_test': prob_uni_test}\n",
        "df_uni_test = pd.DataFrame(data = di_uni_test) # This dataframe returns each word in the test set and it's respective probailities\n",
        "# based on the training probabilities.\n",
        "df_uni_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7JSSi2x-p4zp",
        "outputId": "52b10c36-9c82-4ce7-ef57-6f888037f6e2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Word_uni_test  Prob_uni_test\n",
              "0            BAGHDAD       0.000007\n",
              "1                 --       0.002226\n",
              "2                 An       0.000145\n",
              "3              Iraqi       0.000086\n",
              "4           military       0.000280\n",
              "...              ...            ...\n",
              "318281      personal       0.000110\n",
              "318282       adviser       0.000045\n",
              "318283             ]       0.000096\n",
              "318284             .       0.036184\n",
              "318285     <s t o p>       0.036529\n",
              "\n",
              "[318286 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4658ee0-fb57-421b-9eed-d3e11ed92fea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word_uni_test</th>\n",
              "      <th>Prob_uni_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BAGHDAD</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>--</td>\n",
              "      <td>0.002226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>An</td>\n",
              "      <td>0.000145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Iraqi</td>\n",
              "      <td>0.000086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>military</td>\n",
              "      <td>0.000280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318281</th>\n",
              "      <td>personal</td>\n",
              "      <td>0.000110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318282</th>\n",
              "      <td>adviser</td>\n",
              "      <td>0.000045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318283</th>\n",
              "      <td>]</td>\n",
              "      <td>0.000096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318284</th>\n",
              "      <td>.</td>\n",
              "      <td>0.036184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318285</th>\n",
              "      <td>&lt;s t o p&gt;</td>\n",
              "      <td>0.036529</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>318286 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4658ee0-fb57-421b-9eed-d3e11ed92fea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4658ee0-fb57-421b-9eed-d3e11ed92fea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4658ee0-fb57-421b-9eed-d3e11ed92fea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the perplexity on the test set\n",
        "N_uni_test = len(prob_uni_test)\n",
        "log_sum_uni_test = 0\n",
        "\n",
        "for i in range(N_uni_test):\n",
        "  log_sum_uni_test += np.log(prob_uni_test[i])\n",
        "\n",
        "ppx_test_uni = np.exp(log_sum_uni_test * (-1/N))\n",
        "print(\"The unigram perplexity of the test set: \", ppx_test_uni)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPMSjgP9q5yG",
        "outputId": "ca0d1575-d809-4a3b-d49f-39d694ecdec7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The unigram perplexity of the test set:  3.735634148416777\n"
          ]
        }
      ]
    }
  ]
}